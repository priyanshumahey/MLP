{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron in Numpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple modular multilayer perceptron with one hidden layer built with numpy. It's designed to be very easy to use and apply."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test dataset showcased here is the mnist numbers dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import numbers_dataset, visualize\n",
    "\n",
    "train_set, test_set, train_labels, test_labesl = numbers_dataset(download=False)\n",
    "\n",
    "print(f'Training datset length: {len(train_set)}')\n",
    "print(f'Testing datset length: {len(test_set)}')\n",
    "\n",
    "visualize(train_set, train_labels, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[0].shape\n",
    "\n",
    "ex1 = train_set[:2]\n",
    "\n",
    "ex1.reshape(1, 2, 784)\n",
    "\n",
    "ex1[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layered Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function:\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 1), (10, 1))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def biases(hidden_layer_size, true_output):\n",
    "        biases_1 = np.random.rand(hidden_layer_size, 1) - 0.5\n",
    "        biases_2 = np.random.rand(len(true_output), 1) - 0.5\n",
    "        return biases_1, biases_2\n",
    "\n",
    "biases_1, biases_2 = biases(10, [10,10,10,10,10,10,10,10,10,10])\n",
    "\n",
    "biases_1.shape, biases_2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 784), (10, 10))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weights(inputs, true_output, hidden_layer_size):\n",
    "        weight_1 = np.random.rand(hidden_layer_size, inputs) - 0.5\n",
    "        weight_2 = np.random.rand(hidden_layer_size, true_output) - 0.5\n",
    "        return weight_1, weight_2\n",
    "\n",
    "weight_1, weight_2 = weights(784, 10, 10)\n",
    "weight_1.shape, weight_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.random.rand(784, 1)\n",
    "y_output = np.random.rand(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.89002566],\n",
       "       [ 1.226334  ],\n",
       "       [ 5.13947229],\n",
       "       [ 3.78282446],\n",
       "       [-3.13514197],\n",
       "       [-1.69060064],\n",
       "       [-0.0419171 ],\n",
       "       [ 4.01788239],\n",
       "       [-3.41844396],\n",
       "       [11.65052328]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1 = np.matmul(weight_1, x_input) + biases_1\n",
    "\n",
    "output_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99962568],\n",
       "       [0.77317629],\n",
       "       [0.99417337],\n",
       "       [0.9777481 ],\n",
       "       [0.04168073],\n",
       "       [0.15569687],\n",
       "       [0.48952226],\n",
       "       [0.98232693],\n",
       "       [0.03172399],\n",
       "       [0.99999129]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(output_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    def __init__(self, activation_function, inputs, true_output, hidden_layer_size):\n",
    "        self.activation_function = activation_function\n",
    "        self.input = inputs\n",
    "        self.weights_1, self.weights_2 = self.weights(inputs, true_output, hidden_layer_size)\n",
    "        self.biases_1 = self.biases(inputs, hidden_layer_size)\n",
    "        self.output_dim = np.shape(true_output)\n",
    "        return\n",
    "    \n",
    "    def weights(inputs, true_output, hidden_layer_size):\n",
    "        weight_1 = np.random.rand(inputs, hidden_layer_size) - 0.5\n",
    "        weight_2 = np.random.rand(hidden_layer_size, len(true_output)) - 0.5\n",
    "        return weight_1, weight_2\n",
    "\n",
    "    def biases(hidden_layer_size, true_output):\n",
    "        biases_1 = np.random.rand(hidden_layer_size, 1) - 0.5\n",
    "        biases_2 = np.random.rand(len(true_output), 1) - 0.5\n",
    "        return biases_1, biases_2\n",
    "\n",
    "    def layer_in_to_hid(self):\n",
    "        y_hat_1 = np.matmul(self.weights_1, self.inputs) + self.biases_1\n",
    "        return self.activation_function(y_hat_1)\n",
    "\n",
    "    def layer_hid_to_out(self):\n",
    "        y_hat_2 = np.matmul(self.weights_2, self.layer_in_to_hid()) + self.biases(self.output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
